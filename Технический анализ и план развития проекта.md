# Target Assistant Bot – технический анализ и план развития проекта



## Обзор проекта

**Target Assistant Bot** – это персональный Telegram-бот ассистент, помогающий пользователям формулировать долгосрочные цели, разбивать их на ежедневные задачи и отслеживать прогресс. Бот интегрируется с **Google Sheets** (для хранения целей и задач) и **OpenAI API** (для генерации плана достижения цели и мотивирующих сообщений). Проект активно развивается: в ветке `main` более 100 коммитов (последние – май 2025 года), используются pull request’ы и стандартизированные сообщения коммитов (*Conventional Commits* типа `feat`, `fix`, и т.д.), что обеспечивает понятную историю изменений. Репозиторий открыт под лицензией **MIT**.

## Структура репозитория и содержимое

Проект имеет хорошо структурированное разделение на модули и содержит необходимые конфигурационные файлы:

- **Основные директории кода**:
  - `core/` – ядро приложения (бизнес-логика управления целями и задачами).
  - `handlers/` – обработчики команд Telegram-бота (команды и диалоги).
  - `llm/` – интеграция с языковой моделью (клиент OpenAI для генерации текста).
  - `sheets/` – работа с Google Sheets (класс для взаимодействия с таблицами целей).
  - `scheduler/` – планировщик задач (ежедневные напоминания и задачи; используется AsyncIOScheduler).
  - `utils/` – вспомогательные утилиты (например, логирование, парсинг).
  - `tests/` – модульные тесты для основных компонентов проекта.

- **Документация и вспомогательные файлы**:
  - `docs/` – подробная документация: **Руководство пользователя**, гайд по установке на сервер (Ubuntu 24.04 LTS), описание **архитектуры проекта** и **CHANGELOG**.
  - `README.md` – основное описание проекта (на русском языке, см. ниже).
  - `CHANGELOG.md` – список изменений по версиям.
  - `CONTRIBUTING.md` – рекомендации для контрибьюторов (присутствует, содержит правила для участников разработки).
- **Конфигурационные файлы** (в корне):
  - `.env.example` – пример файла переменных окружения (требуется скопировать в `.env`); содержит шаблон настроек: токен Telegram-бота `TELEGRAM_BOT_TOKEN`, путь к учетным данным Google API `GOOGLE_CREDENTIALS_PATH` и др..
  - `config.py` – загрузка и обработка конфигурации (чтение переменных окружения, настройка констант).
  - `requirements.txt` и `pyproject.toml` – зависимости проекта (см. раздел зависимости ниже).
  - `Dockerfile` и `docker-compose.yml` – настройки для контейнеризации и запуска в Docker.
  - `deploy/` – скрипты деплоя: юнит-файл **systemd** `targetbot.service` и скрипт автообновления `update-bot.sh` (для установки cron-задачи). Эти файлы позволяют развернуть бота как сервис на сервере и каждые 15 минут подтягивать обновления из Git.
  - `.pre-commit-config.yaml` – конфигурация хуков *pre-commit* (автоматические проверки качества кода перед коммитом).
  - `.coveragerc` – настройки измерения покрытия тестами (например, исключение определённых файлов из подсчёта).
  - `.editorconfig` – общие настройки форматирования кода.
  - `.gitignore` – список исключённых из репозитория файлов.
  - `.secrets.baseline` – baseline для сканера секретов (для предотвращения утечек чувствительных данных в коде).
- **Лицензия**: Файл `LICENSE` с текстом MIT лицензии присутствует в репозитории.

Таким образом, структура репозитория охватывает все основные аспекты: выделены отдельные модули под каждую подсистему бота, имеются примеры конфигурации и скрипты для развёртывания, а также инструменты поддержания качества кода.

## Описание функциональности и документация

**README.md** – центральный документ, написанный на русском языке. Он содержит:

- **Краткое описание проекта** и назначение бота (Telegram-ассистент для постановки целей с сохранением данных в Google Sheets и интеграцией OpenAI).
- **Список команд бота** с описанием каждой:
   `/start` – начать работу;
   `/help` – справка;
   `/setgoal` – установить новую цель;
   `/today` – получить задачу на сегодня;
   `/check` – отметить выполнение задачи;
   `/status` – показать прогресс;
   `/motivation` – получить мотивирующее сообщение;
   `/cancel` – отменить текущую операцию;
   `/reset` – сбросить все цели пользователя (полное удаление данных).
- **Хранение данных целей**: объясняется, что для каждого пользователя создаётся индивидуальная Google-таблица с двумя листами – **«Информация о цели»** (параметры цели) и **«План»** (ежедневные задачи с автоматическим обновлением статуса). Таким образом, из коробки поддерживается **раздельное хранение данных для каждого пользователя** (каждый получает свою таблицу).
- **Инструкции по запуску** (раздел "Быстрый старт"):
  - С использованием виртуального окружения (venv): команды для установки зависимостей, копирования `.env` и запуска бота локально.
  - С помощью **Docker Compose**: примеры команд для клонирования репозитория, настройки `.env` и запуска контейнера.
- **Руководство по деплою на сервер (systemd)**: пошаговое описание установки бота на сервере Ubuntu — создание пользователя, настройка Python venv, установка зависимостей, копирование `targetbot.service` в `/etc/systemd/system`, запуск службы и настройка cron для `update-bot.sh` (обновление из Git). Эта инструкция позволяет развернуть бота как системную службу, автоматически перезапускаемую и обновляемую.
- **Ссылки на подробную документацию**: раздел README "Документация" содержит ссылки на файлы в директории `docs/`:
  - **Руководство пользователя** – детальное описание использования бота (вероятно, пошаговые сценарии: как задать цель, как отмечать выполнение, часто задаваемые вопросы и т.д.).
  - **Установка на Ubuntu 24.04 LTS** – расширенная версия инструкции деплоя, возможно с пояснениями по зависимостям.
  - **Архитектура проекта** – документ, описывающий внутреннее устройство бота, ключевые компоненты и их взаимодействие.
  - **Список изменений** – фактически `CHANGELOG.md` с перечислением версий и нововведений.
- **Информация о лицензии**: указано, что проект распространяется по лицензии MIT.

В целом, документация проекта можно охарактеризовать как **очень качественную и полную** для текущей стадии разработки. Новому пользователю или разработчику предоставлено всё необходимое:

- Есть краткое описание и цели проекта.
- Подробно расписаны возможности (команды бота).
- Пошаговые инструкции для запуска в разных средах (локально, Docker, на сервере).
- Существует отдельное пользовательское руководство и техническое описание архитектуры в `docs/`.
- В README присутствуют бейджи статуса: в шапке отображаются статус CI, статус тестов, поддерживаемая версия Python и лицензия, что демонстрирует прозрачность в отношении качества сборки и покрытия.

**Недостатки документации:** Единственный заметный пробел — **отсутствие информации на английском языке**. В настоящее время README и руководства доступны только на русском, что ограничивает международное участие. *Дополнительно (внешняя рекомендация):* имеет смысл добавить хотя бы краткую англоязычную версию README (или двуязычный README) и перевести основные комментарии в коде на английский, чтобы привлечь более широкую аудиторию разработчиков.

Также, раздел "About" на странице репозитория GitHub не заполнен: отображается стандартное сообщение *“No description, website, or topics provided.”*. Это значит, что в настройках репозитория не указано краткое описание проекта и не проставлены теги (topics). *Внешние рекомендации отмечают*, что стоило бы добавить описание (на русском и английском) и тематические теги (например, `telegram-bot`, `goal-tracking`, `productivity`) – это улучшит обнаружимость проекта на GitHub.

## Зависимости и конфигурация окружения

Проект написан на **Python 3.10+** (судя по бейджу, поддерживаются Python 3.10 и 3.11; совместимость с 3.12 также подтверждена обновлёнными зависимостями). Используемые библиотеки актуальны и регулярно обновляются разработчиком. Ниже перечислены ключевые зависимости и их состояние:

- **python-telegram-bot** – версия 22.0. Эта версия (релиз 2023/03) переведена на полностью асинхронную модель работы с Telegram API. Проект своевременно обновился с v21 на v22, что хорошо – используется современный async API.
- **APScheduler** – версия 3.11.0. Актуальная стабильная версия планировщика задач; библиотека используется для ежедневных напоминаний (через AsyncIOScheduler).
- **OpenAI API (openai)** – версия >=1.77,<2.0. Одна из последних версий SDK (начало 2025 года). Проект указал диапазон версий, что позволяет получать обновления вплоть до 1.x. Разработчик уже поднимал версию (изначально была ~1.13), следя за обновлениями OpenAI.
- **Google API Client** – `google-api-python-client >=2.123`. Современная версия клиента для работы с Google API (таблицы, аутентификация). Проект использует Google API для доступа к Google Sheets через сервисные аккаунты.
- **gspread** – версия **6.0.2**, жестко зафиксирована. Это библиотека-обёртка над Google Sheets API. Актуальная версия на момент анализа – 6.2.0, однако разработчик зафиксировал 6.0.2 по причине совместимости с `gspread-asyncio`. Дело в том, что `gspread-asyncio` 2.0.0 официально поддерживает gspread 5.x и 6.0.*, но может не работать с 6.1+ (изменился API). Чтобы избежать проблем, версия закреплена (коммит с сообщением *“pin gspread 6.0.2 to satisfy gspread-asyncio”* упоминается в истории). Этот шаг предотвращает случайные сбои, хотя и оставляет проект на слегка устаревшей версии.
- **gspread-asyncio** – версия 2.0.0. Асинхронная надстройка для gspread, позволяет вызывать Google Sheets API без блокировки. Проект использует эту библиотеку для фоновых операций с таблицами. Последний релиз библиотеки был в 2024 г.; новых версий пока нет. *Внешние эксперты* советуют следить за её развитием: если поддержка застынет и не будет обновлений под новые версии gspread, в будущем можно рассмотреть переход на альтернативы (например, библиотека **aiospread**, форк gspread с нативной async-поддержкой) или реализовать свой механизм доступа к API напрямую. Пока же текущая связка (`gspread==6.0.2` + `gspread-asyncio 2.0.0`) работоспособна.
- **Google Auth** – библиотеки для аутентификации: `google-auth >=2.40` и `google-auth-oauthlib >=1.2`. Они используются для OAuth2 и авторизации сервисного аккаунта при доступе к Google Sheets. Версии актуальные (2024-2025 гг.), поддержка Python 3.12 присутствует.
- **Python Dotenv** – >=1.0.0. Используется для загрузки переменных окружения из `.env`. Версия свежая (1.0 – 2023 год).
- **Pytz** – >=2024.1. Традиционная библиотека временных зон (в Python 3.9+ может быть заменена на встроенный `zoneinfo`, но использование pytz не критично).
- **Tenacity** – >=8.3. Библиотека для повторных попыток (retry). Проект подключил её (вероятно, для повторных вызовов к API при неудаче), версия актуальна.
- **Structlog** – >=24.1. Современная библиотека для структурированного логирования. Ее наличие говорит о том, что логирование в проекте настраивается в JSON-формате, возможно, для интеграции с внешними системами мониторинга.
- **Prometheus-client** – >=0.20.0. Библиотека для экспорта метрик. В коде README или описании команд бот никак не упоминает метрики, но наличие зависимость говорит о том, что разработчик **заложил возможность экспортировать метрики** (возможно, через отдельный endpoint `/metrics` или сбор внутренних показателей работы бота). Пока не ясно, используется ли это в полной мере.
- **Sentry SDK** – >=1.43. Интеграция с Sentry для отслеживания ошибок. Судя по зависимостям, бот при старте может инициализировать Sentry (при наличии DSN в переменных окружения), чтобы автоматически отправлять неперехваченные исключения. Версия SDK близка к последней (актуальная ~1.49), что хорошо; рекомендуется обновлять её по мере выхода новых версий, но критичных проблем совместимости нет.
- **Dev-зависимости** (для разработки и CI):
  - **Black** – >=24.4.2, форматер кода.
  - **Ruff** – >=0.4.1, современный быстрый линтер, заменяющий flake8/pyLint (версия 0.4.x на начало 2025, рекомендуется обновляться, т.к. Ruff быстро развивается).
  - **Mypy** – >=1.10, статический анализ типов.
  - **Pytest** – >=8.0, фреймворк тестирования. Проект обновлён до Pytest 8 (который требует Python 3.8+), что подтверждает поддержку современного окружения.

В целом, **состояние зависимостей отличное**: большинство библиотек либо актуальны, либо обновлены совсем недавно. Разработчик явно следит за версиями – перед выпуском релиза 1.2 ряд пакетов был обновлён до свежих релизов, улучшая совместимость с новыми версиями Python. Особое внимание уделено связке Google Sheets: в проекте сделано обоснованное решение зафиксировать версию `gspread` до выхода совместимой версии `gspread-asyncio` или перехода на альтернативный подход.

**Dependabot** настроен, но нужно проверить (автоматические Pull Request’ы от бота не наблюдаются, все обновления зависимостей делаются вручную разработчиком). *В качестве дополнительной идеи*, можно подключить Dependabot для проверки обновлений зависимостей и уведомления о известных уязвимостях – это упростит поддержание библиотек в актуальном состоянии и повысит безопасность.

## Инфраструктура разработки (CI/CD, тесты, качество кода)

Проект включает полноценный набор средств для обеспечения качества:

- **Pre-commit хуки**: конфигурация `.pre-commit-config.yaml` задаёт автоматический запуск линтеров и форматтера при каждом коммите. Можно уверенно предположить, что там подключены **Black**, **Ruff**, а также **mypy** для быстрого локального обнаружения проблем стиля и типизации. Это гарантирует единообразный стиль кода и отсутствие тривиальных ошибок до попадания изменений в репозиторий.
- **Юнит-тесты**: В каталоге `tests/` присутствует набор тестов, покрывающих основные аспекты. Судя по истории коммитов и файлам конфигурации, тестами охвачены ключевые модули (например, имитируется работа с Google Sheets через заглушку `DummySpreadsheet` и проверяется бизнес-логика постановки задач). Покрытие тестами постоянно контролируется: из файлов и коммитов видно, что в процессе разработки минимальный порог покрытия **повышался с 50% до 70%, а затем до 80%**, что означает — CI **падает, если покрытие ниже 80%**. На текущий момент проект достиг ~80% покрытия кода тестами, что является отличным показателем для бота. В `.coveragerc` внесены необходимые исключения (например, можно исключить из подсчёта код генерации Telegram-команд или файл `main.py`), чтобы метрика была репрезентативной.
- **GitHub Actions (CI)**: Настроен workflow непрерывной интеграции. В README отображаются бейджи сборки CI и статуса тестов, что говорит об успешно работающем пайплайне. Хотя сам YAML workflow не приведён здесь, анализ коммитов и внешние отчёты позволяют понять, какие этапы выполняются в CI:
  - Запуск **юнит-тестов** на различных версиях Python (вероятно, матрица включает Python 3.10 и 3.11, возможно и 3.12) и на различных ОС. Это подтверждается упоминанием “CI matrix” и тем, что проект заявляет поддержку нескольких версий Python.
  - Подсчет **coverage** и проверка, что он не опускается ниже установленного порога (80%). Этот шаг встроен в CI, поэтому каждый Pull Request проверяется на достаточное покрытие тестами.
  - Возможен запуск **линтеров и mypy**: хотя явных упоминаний об отдельном этапе линтинга нет, скорее всего, благодаря pre-commit большинство стильовых ошибок отсекается ещё до CI. Тем не менее, *рекомендовано* добавить отдельный job в Actions для запуска `ruff` и `mypy` на всякий случай – чтобы гарантирванно не пропустить проблемы, особенно если кто-то контрибьютит без локального pre-commit.
  - **Сборка Docker-образа** не настроена в CI (признаков публикации образов или авто-деплоя нет). Предполагается, что развертывание осуществляется вручную администратором, следуя инструкции (что приемлемо для личного проекта).
  - **Автоматический деплой** на сервер также не реализован через CI – вместо этого предложен скрипт `update-bot.sh` + cron на сервере (каждые 15 минут тянущий `git pull`). Такой метод обновления прямо из ветки `main` – простой, хотя и рискованный: если в `main` попадает ошибка, она сразу развернётся на сервере. Обычно в продакшен-практике главную ветку защищают и выкатывают только проверенные релизы. Здесь же main = prod, но благодаря хорошему покрытию тестами и CI риски снижены. *Внешние эксперты* дополнительно рекомендуют со временем перейти от авто-пулла из `main` к более контролируемому деплою – например, выкатывать на сервер только помеченные релизы (теги) или реализовать CD-пайплайн в Actions с ручным подтверждением деплоя.
- **Логирование и мониторинг**: как отмечалось, проект включает Sentry для сбора ошибок и, возможно, Prometheus для метрик. Ошибки, происходящие в продакшене, будут отправляться в систему мониторинга (при условии настроенного Sentry DSN) – это повышает поддерживаемость. Метрики (если они будут экспортироваться) позволят отслеживать, например, частоту выполнения задач или состояние планировщика.
- **Реакция на сбои в CI**: В истории есть примеры, где автор оперативно исправлял проблемы, выявленные автоматическими тестами. Например, коммит *“fix(async): ensure AsyncIOScheduler has explicit event_loop for CI”* показывает, что тесты падали из-за нюансов AsyncIO, и разработчик внёс исправление (указал явный event loop для планировщика). Это говорит о внимательном отношении к стабильности: даже тонкие баги выявляются и устраняются, благодаря чему ветка `main` остаётся в рабочем состоянии.

В целом, процесс разработки выстроен профессионально: код форматируется и проверяется автоматически, все новые изменения проходят через CI с тестами, достигается высокий процент покрытия, фиксируются изменения в CHANGELOG. *Дополнительно можно улучшить* процесс, настроив **шаблоны для Issue и Pull Request** (в репозитории сейчас нет папки `.github/ISSUE_TEMPLATE` и файла PR-шаблона). Их добавление упростит внешним участникам подачу баг-репортов и предложений по улучшению.

## Архитектура и качество кода

Архитектура проекта следует принципам разделения обязанностей и использует современные возможности Python. Основные модули и их взаимодействие описаны также в документе «Архитектура проекта» (в `docs/`). Здесь кратко охарактеризуем ключевые аспекты:

- **Модульность**: Каждая подсистема бота вынесена в отдельный модуль, что повышает читаемость и поддерживаемость. Например, `GoalManager` (в `core`) отвечает за логику целей, `SheetsManager` (в `sheets`) инкапсулирует работу с таблицей, `LLMClient` (в `llm`) – за вызовы OpenAI. Обработчики команд (в `handlers`) обращаются к этим менеджерам, но сами по себе мало зависят от конкретной реализации хранения или AI. Такой дизайн упрощает модификацию отдельных частей.
- **Асинхронность**: Проект обновлён до библиотеки **python-telegram-bot v22**, которая требует использования `asyncio`. Весь код команд переведён на `async def`, задачи планировщика (`apscheduler`) тоже выполняются в AsyncIO-петле. Это означает, бот способен выполнять несколько операций параллельно (например, опрашивать OpenAI и одновременно не "зависать" для других пользователей). Наличие команды `/today_async` (упомянутой во внешнем обзоре) говорит о том, что архитектура изначально учитывала возможность **длительных операций** – вероятно, планировалось, что генерация плана на день может выполняться асинхронно, возвращая результат позже. Сейчас основная команда `/today` работает синхронно (моментально формирует задачу на основе уже разбитой цели), поэтому отдельная async-версия не используется явным образом.
- **Работа с данными и ограничениями**: Бот хранит все пользовательские данные в Google Sheets, что удобно для пользователя (прозрачность и доступ через Google). Однако это накладывает ограничения: взаимодействие с API Google не мгновенно и имеет квоты. В коде реализована базовая поддержка таких сценариев: например, используются *retry*-механизмы (в некоторых местах, возможно, вручную через `try/except` и повтор вызова, либо с использованием библиотеки `tenacity`) для повторения запросов при временных ошибках. Также, благодаря `apscheduler`, бот может планировать ежедневные задачи на определённое время (например, каждое утро отправлять новую задачу).
- **Логирование и ошибки**: С помощью `structlog` и интеграции **Sentry**, в проекте выстроена система логирования. Критические операции обёрнуты в блоки try/except с логированием ошибок. Если что-то пойдёт не так (например, ошибка сети при обращении к OpenAI), это не ломает весь бот – ошибка логируется и, вероятно, отправляется в Sentry, чтобы разработчик мог ее проанализировать. Это повышает отказоустойчивость бота в реальном использовании.
- **Тестируемость кода**: Структура кода упрощает его тестирование – многие функции разделены и могут быть протестированы в отрыве от внешних API. В тестах, судя по упоминаниям, используются заглушки, например, для Google Sheets (`DummySpreadsheet` имитирует таблицу). Это позволяет запускать CI без реальных запросов к внешним сервисам, а значит – быстро и изолированно проверять логику.

**Обнаруженные ограничения архитектуры** (по состоянию на текущий код):

1. **Одна цель на пользователя** – по текущей логике каждый пользователь в любой момент работает только над одной активной целью. Команда `/reset` удаляет текущую цель, после чего можно установить новую через `/setgoal`. Нет штатной возможности вести несколько целей одновременно (например, личная цель и рабочий проект, параллельно). Это подтверждается и фактом, что на одну Google-таблицу хранится информация по одной цели. Для расширения функциональности (см. новый функционал ниже) потребуется модифицировать эту часть.
2. **Частые обращения к Google Sheets** – если бот на каждого пользователя при каждом запросе `status` или `today` обращается к Google Sheets API, это может быть неэффективно. Сейчас, вероятно, каждый вызов команды читает/обновляет таблицу напрямик. При небольшом числе пользователей это не проблема, но при росте нагрузки может потребоваться оптимизация (кэширование данных о цели в памяти между запросами, пакетные обновления).
3. **Жёсткая связность менеджеров** – например, `GoalManager` внутри себя использует `SheetsManager` и `LLMClient`, создавая их экземпляры напрямую. Это означает, что для тестирования или замены Google Sheets на другую БД нужно менять код `GoalManager`. Отсутствуют абстракции интерфейсов – например, нет явного интерфейса хранения данных, который можно было бы замокать или заменить (используется конкретный класс для Google Sheets).
4. **Отказоустойчивость и ограничение rate-limit** – механизм повторных попыток (retry) реализован нецентрализованно. Библиотека `tenacity` подключена, но не ясно, используется ли она во всех необходимых местах. Возможно, часть повторов сделана вручную, а глобального декоратора с backoff для, скажем, всех запросов к OpenAI или Google Sheets, нет. Аналогично, нет явного **ограничения частоты запросов** (rate limiting) на пользователя – теоретически один пользователь мог бы дергать `/motivation` очень часто и исчерпать лимит API. Пока бот в личном использовании это не критично, но при расширении аудитории стоит учитывать.

- **Документация кода**: На уровне кода не все публичные классы и функции имеют docstring-документацию. Это затрудняет новым разработчикам быстро понять некоторые методы без заглядывания в `docs/`.

В остальном, код стильный и современный: используется аннотирование типов (mypy проходит), активно применяются *dataclass* там, где удобно, функции названы понятно, модульность высокая. Внешний аудит отмечает высокую читаемость кода и единообразие стиля благодаря автоформатированию.

*Дополнительно, со стороны внешних рекомендаций предлагается* ряд **архитектурных улучшений**:

- Ввести уровень абстракций для хранилища и LLM-клиента (например, определить интерфейсы `StorageInterface` и `LLMInterface`, а реализацию для Google Sheets и OpenAI передавать в `GoalManager` через dependency injection). Это снизит связность и упростит добавление других типов хранилищ или AI при необходимости.
- Расширить внутреннюю логику на **несколько целей на пользователя** (поддержать множество целей). Для этого, в структурах данных должен появиться идентификатор цели (goal_id), а все методы, работающие с целями/задачами, должны принимать этот идентификатор. Потребуется модификация `SheetsManager` (чтобы в одной таблице или в разных таблицах хранить несколько целей) и соответствующие изменения в командах бота.
- **Повысить эффективность работы с Google API**: добавить кэширование часто запрашиваемых данных (например, результата последнего запроса `today` на текущий день, списка задач и статусов, чтобы при повторном `/status` не ходить заново в Google API), а также использовать пакетные запросы (`batch_update` в gspread) для записи нескольких изменений сразу.
- **Улучшить отказоустойчивость**: унифицировать использование `tenacity` для всех операций, которым полезны повторы при неудаче (например, запросы к OpenAI, которые могут временно проваливаться); реализовать класс **RateLimiter** для ограничения частоты определённых действий (например, не более N обращений к OpenAI в минуту на пользователя), чтобы избежать удара в ограничения API.
- Дополнительно убедиться, что интеграция Prometheus (если планируется) реализована – например, можно измерять время ответа OpenAI или количество выполненных планов, и эти метрики экспонировать для мониторинга.

Все вышеперечисленные улучшения не являются срочными для работоспособности, однако станут актуальны по мере масштабирования проекта и увеличения числа пользователей/целей, а также при открытии проекта для сторонних контрибьюторов.

## План развития (Roadmap)

Ниже представлен подробный **план действий** по развитию и улучшению Target Assistant Bot. Задачи перечислены в порядке приоритетности, учитывая **простоту реализации**, **полезность для дальнейшего развития** и **необходимость с точки зрения требований**. Каждый пункт содержит описание сути задачи, её цель/обоснование и возможные подходы к реализации:

### 1. Быстрые улучшения репозитория и проекта

1. **Актуализировать файл LICENSE** – *(\*Легко, необходимо юридически\*)*. Убедиться, что в `LICENSE` содержится полный текст MIT-лицензии (если сейчас там шаблон или отсутствует имя автора – вписать его). Явное наличие лицензии уже есть, но важно, чтобы текст соответствовал стандартному MIT, это снимет вопросы у потенциальных пользователей о правовом статусе кода.

2. **Создать шаблоны Issue и Pull Request** – *(\*Легко, полезно для открытой разработки\*)*. Внести вклад в проект другим будет проще, если в репозитории появятся:

   - Шаблоны баг-репорта и запроса фичи (папка `.github/ISSUE_TEMPLATE/` с файлами `bug_report.md`, `feature_request.md`). Они помогут структурировать получаемые от пользователей задачи.
   - Шаблон описания Pull Request (`.github/PULL_REQUEST_TEMPLATE.md`) с чеклистом (запуск тестов, описание изменений, ссылка на проблему и т.д.).

   Эти файлы стандартизируют процесс обсуждения проблем и изменений. *Пример реализации:* создать папку `.github`, внутри неё файлы Markdown с перечнем полей (см. документацию GitHub или позаимствовать из популярных open-source проектов).

3. **Дополнить раздел “Contributing”** – *(\*Легко, полезно для внешних участников\*)*. Файл `CONTRIBUTING.md` уже есть, но его стоит проверить и расширить. Следует описать:

   - Требования к окружению (версия Python, как установить зависимости, запуск тестов).
   - Процесс запуска pre-commit локально (`pre-commit install`) для тех, кто форкнет проект.
   - Стиль коммитов (используется Conventional Commits – указать, какие типы есть: feat, fix, etc.).
   - Правила оформления кода (ссылка на использование Black, Ruff – но это и так автоматизировано).
   - Порядок создания Pull Request (желательно связать с Issue, проход всех тестов перед review).

   Чёткое руководство для контрибьюторов привлечёт более качественные внешние вклады.

4. **Добавить бейдж покрытия тестов** – *(\*Легко, косметически полезно\*)*. Порог покрытия проверяется в CI, можно вывести **badge** покрытия (например, с Codecov или покрытия, загруженного в GitHub Actions) прямо в README. Это будет мотивировать поддерживать тесты. Также можно добавить бейдж Dependabot (если включите его) для статуса зависимостей. Эти значки в README сразу показывают качество проекта.

### 2. Улучшение документации и международной доступности

1. **Подготовить английскую версию README** – *(\*Средне, полезно для расширения аудитории\*)*. Перевести основной README.md на английский или сделать второй файл README_EN.md (и сослаться на него). Достаточно изложить суть проекта, инструкцию по запуску и основные команды. Комментарии в коде для публичных методов тоже желательно дублировать на английском. Цель – сделать проект понятным не только русскоязычным пользователям, что может привлечь зарубежных коллег и пользователей. *Способ реализации:* либо поддерживать двуязычный README (разделив на английский и русский сегменты), либо две версии файла. Можно начать хотя бы с английского раздела "Description" и "Usage" в existing README.

2. **Обновление и расширение существующей документации** – *(\*Средне, полезно\*)*. Проверить документы в `docs/` на актуальность:

   - **Руководство пользователя**: дополнить примерами использования, особенно с учётом будущей поддержки нескольких целей. Добавить скриншоты взаимодействия с ботом в Telegram, если возможно, чтобы проиллюстрировать процессы (например, постановка цели, получение задачи, отметка выполнения).
   - **Архитектура проекта**: обновить диаграммы или описание, если архитектура будет меняться (например, появится поддержка множества целей).
   - **Презентация (PDF)**: прилагаемая презентация должна отражать текущее состояние проекта. Если в ней устаревшая информация, ее нужно переработать или пометить как архив.

   Хорошая документация снизит порог входа новых разработчиков в проект.

3. **Добавить примеры сценариев использования** – *(\*Средне, повышает понятность для пользователей\*)*. В README или в руководстве стоит описать небольшой сценарий: например, *“Пользователь ставит цель ‘Написать книгу за 3 месяца’. Бот с помощью OpenAI предлагает разбивку по главам и ежедневным задачам. Пользователь каждый день получает задачу `/today` и отмечает её выполненной через `/check`. Командой `/status` он видит прогресс (например, 5/90 задач выполнено, 5% пути).”* Такой сквозной пример поможет пользователям понять ценность бота. Сейчас по описанию команд понятно, *что они делают*, но не сразу ясно, как выглядит полный цикл работы с ботом.

### 3. Новые функции: поддержка нескольких пользователей и целей

1. **Масштабирование на нескольких пользователей** – *(\*Средне, необходимо\*)*. Бот изначально разрабатывается как личный, но требования предполагают поддержку **до 20 пользователей** одновременно. В принципе, архитектура уже позволяет работать с разными пользователями (данные изолированы в отдельных Google-таблицах, идентификатор пользователя Telegram используется для доступа к нужной таблице). Нужно провести тестирование с несколькими пользователями: запустить бота в групповом чате или с разных аккаунтов, убедиться, что параллельные обращения не конфликтуют. Особое внимание:

   - Проверить, нет ли глобальных переменных, хранящих состояние текущей цели **без учёта user_id**. Если есть (например, текущий шаг мастера), заменить их на хранение в контексте диалога Telegram (PTB Context) или привязать к user_id.
   - Убедиться, что планировщик (apscheduler) отличает задачи разных пользователей. Вероятно, задачи добавляются с идентификатором пользователя в качестве части имени job. Если нет – нужно включить user_id в идентификатор задач, иначе две ежедневные задачи от разных пользователей могут коллизировать.

   Результатом этого шага должен стать **бот, способный обслуживать 20+ пользователей**, не мешая данным друг друга.

2. **Поддержка нескольких целей на одного пользователя** – *(\*Сложно, необходимо для расширения функционала\*)*. Это крупное изменение, которое потребует продумать и реализовать новую логику:

   - **Структура хранения**: в персональной Google-таблице одна таблица на пользователя с разделением целей по разным листам/страницам. На первом листе информация о всех целях пользователя и их номера (идентификатор).
   - **Изменения в `SheetsManager`**: нужно научить методы создания/чтения целей работать с указанным идентификатором цели или именем листа. Например, `create_goal()` будет создавать новый лист(ы) в таблице или новую таблицу и возвращать его идентификатор; `get_today_task(goal_id)` – выбирать соответствующий лист “План” именно для этой цели. Можно сопоставлять каждому goal_id пару листов: `"Goal1_Info"`, `"Goal1_Plan"`, либо хранить план и инфо на одном листе в разных ячейках (но лучше разделить для простоты).
   - **Изменения в `core/GoalManager`**: сейчас, вероятно, имеется свойство, держащее одну текущую цель. Придется переделать методы `set_goal`, `check_task`, `get_status` – чтобы они принимали указатель на цель. Возможно, стоит хранить **словарь целей пользователя** в памяти или в файле: ключ – goal_id, значение – структурка с текущим состоянием или ссылкой на Google Sheet. Однако, чтобы не дублировать данные, лучше каждый раз читать актуальное из Google Sheets (с caching, см. ниже).
   - **Новые команды/UX**: нужно позволить пользователю управлять несколькими целями. Возможные подходы:
     - Команда `/setgoal` может остаться для создания **новой цели**. Если уже есть активная цель, бот должен не перетирать её, а добавить новую. Может потребоваться спросить у пользователя название цели, чтобы различать (либо генерировать порядковый номер).
     - Команда `/goals` или `/listgoals` – показать список текущих целей с индексами. Пользователь должен иметь способ переключаться между целями, например, командой `/switchgoal <номер>` или через меню.
     - Команды `/today`, `/status`, `/check` – по умолчанию действовать на “текущую активную цель”. После ввода `/setgoal` нескольких целей, надо где-то хранить, какая цель сейчас активна для пользователя. Например, команда `/switchgoal` меняет флаг активной цели. Либо же можно расширить эти команды параметром: `/today 2` – задача по второй цели. Но в чат-ботах передавать параметр числом не всегда удобно, лучше сделать явную команду переключения.
     - Команда `/reset` – при множественных целях нужно уточнение: либо удаляет **все** цели (как сейчас), либо очищает только текущую/указанную цель. Вероятно, стоит иметь `/resetgoal <id>` для удаления конкретной цели, и `/resetall` для полного сброса.
   - **Миграция данных**: не нужна, все таблицы будут созданы заново.

   Это изменение затронет многие части, но принесёт большую гибкость в использовании бота. Пользователь сможет вести параллельно до 10 различных целей, переключаясь между ними. В реализацию обязательно включить **обновление документации**: описание новых команд, обновление пользовательского руководства с примером нескольких целей.

### 4. Архитектурные и кодовые улучшения

1. **Рефакторинг зависимостей между модулями** – *(\*Сложно, полезно для поддерживаемости\*)*. После внедрения многопользовательской и многозадачной поддержки код усложнится, и это хорошее время внедрить более гибкую архитектуру. Следует реализовать **инверсию зависимостей** там, где сейчас жёсткая связка:

   - Определить абстрактные базовые классы (протоколы) для **хранилища целей** и для **LLM**. Например, `StorageInterface` с методами `save_goal`, `load_goal`, `update_task_status` и `LLMInterface` с методом `generate_plan(goal_text)`.
   - Реализации: `SheetsStorage` (реализует StorageInterface, работает через gspread) и `OpenAIClient` (реализует LLMInterface). В `GoalManager` вместо создания конкретных объектов, получать их через конструктор.
   - Можно использовать паттерн **Dependency Injection** – передавать зависимости либо вручную при создании (`GoalManager(storage=SheetsStorage(), llm=OpenAIClient())`), либо подключить простейший контейнер (например, библиотеку `dependency-injector`) для более масштабируемого решения.

   Такой рефакторинг облегчит тестирование (можно подставить в `GoalManager` фейковое хранилище в тестах вместо Google Sheets) и откроет путь к расширению: например, если захотите хранить данные не в Google Sheets, а в базе данных, достаточно будет написать новый класс хранилища без переписывания логики целей.

2. **Кэширование данных Google Sheets** – *(\*Средне, повысит эффективность\*)*. Чтобы снизить нагрузку и задержки при частых запросах, внедрить простой кэш для данных целей/задач:

   - Рассмотреть использование декоратора `functools.lru_cache` для методов, получающих данные, например, список задач на сегодня. Кэш можно делать ключом на запрос по user_id + goal_id (и возможно дата). Это подойдет, если данные не меняются слишком часто. После изменения (например, пользователь отметил задачу выполненной) – кэш нужно сбрасывать (в lru_cache это можно сделать либо не использовать кэш на функции записи, либо обновлять вручную).
   - Альтернативно, использовать in-memory хранилище типа Redis (но это, возможно, избыточно для данного случая).

   Начать можно с lru_cache на наиболее частые операции: получение списка сегодняшних задач, получение параметров цели. С небольшим размером (например, кэшировать последние 128 запросов) – этого хватит для 20 пользователей с запасом. Это даст мгновенный отклик на повторные `/status` или `/today` (если в тот же день вызывается несколько раз).

3. **Пакетные обновления Google Sheets** – *(\*Средне, повысит эффективность\*)*. Изучить возможности библиотеки `gspread` по batch-операциям (например, `batch_update`). Если, к примеру, бот за один шаг должен отметить сразу несколько задач выполненными или внести несколько строк, это можно сделать одним вызовом API вместо нескольких. В текущем сценарии бот обычно добавляет по одной строчке или ставит одну отметку, но если будет функциональность типа "обновить сразу весь план" – batch позволит ускорить. Этот пункт не критичен, но имейте в виду возможность оптимизировать взаимодействие с Google API.

4. **Унификация retry-логики с Tenacity** – *(\*Легко, повышает надёжность\*)*. Внедрить декораторы `@retry` из библиотеки **Tenacity** для операций, склонных к временным сбоям:

   - Оботрать вызовы OpenAI (`LLMInterface.generate_plan`) декоратором, чтобы при временной ошибке от API (например, Rate Limit или Timeout) бот сделал несколько повторов с экспоненциальной задержкой. Это избавит от необходимости писать вручную try/except каждый раз.
   - Аналогично, обернуть критичные взаимодействия с Google Sheets (чтение/запись) – по крайней мере 1 повтор при ошибке сети.

   Параметры Tenacity стоит настроить аккуратно: например, максимум 3-5 попыток, задержка сначала 1 секунда, увеличиваясь до ~10 секунд. Если после всех попыток не удалось, бросить исключение и залогировать в Sentry, чтобы не зависать бесконечно. Декоратор Tenacity также поможет устранить дублирование кода, если сейчас где-то retry реализован вручную.

5. **Реализация ограничения частоты (Rate Limiting)** – *(\*Средне, повысит устойчивость\*)*. Чтобы бот не позволял одному пользователю (или всей системе) перегрузить внешние API, ввести ограничитель:

   - Можно реализовать класс `RateLimiter` (как в внешнем примере) или использовать готовые токен-бакет библиотеки.
   - Простейший подход: хранить в памяти таймштампы последних N вызовов для каждого ключа (например, ключ – user_id для OpenAI или глобальный ключ для Google API, если у Google есть общий лимит на проект). Если новый вызов превышает лимит (например, >60 запросов OpenAI в час для данного пользователя), либо откладывать его, либо возвращать пользователю предупреждение (например: "⚠️ Слишком часто запрашиваются данные, пожалуйста, подождите").

   На практике, с 20 пользователями вряд ли вы упрётесь в лимиты OpenAI (которые обычно несколько тысяч запросов в день) или Google Sheets, но превентивно такой механизм не помешает, особенно если бот станет популярнее. Rate limiting также защитит от сценариев, когда из-за бага бот может уйти в бесконечный цикл запросов – ограничитель прервет шквал и даст системе оставаться стабильной.

6. **Расширение логирования и мониторинга** – *(\*Средне, полезно для поддержки\*)*. Раз уж подключены `prometheus-client` и Sentry, можно:

   - Добавить несколько метрик Prometheus: например, время генерации плана (длительность вызова OpenAI), количество целей у каждого пользователя, число выполненных задач. Экспортировать их (например, с помощью HTTPHandler, если не конфликтует с Telegram).
   - Настроить алерт: например, если бот не смог успешно выполнить ежедневную задачу (Job в `apscheduler`) более X дней – отправить уведомление. Такое можно реализовать через Sentry (выбросить кастомное исключение, которое попадет в Sentry, а там настроить алерт) или через Prometheus Alertmanager, если внедряется метрика "успешное ежедневное задание".

7. **Повышение информативности кода** – *(\*Средне, улучшит поддерживаемость\*)*. Постепенно добавить **docstrings** ко всем основным классам и методам (особенно в `core`, `sheets`, `llm`). Описывать аргументы, возврат и возможные исключения. Это облегчит жизнь вам же и коллегам в будущем, когда нужно будет вспомнить, что делает та или иная функция. Например, методы `GoalManager.set_new_goal`, `SheetsManager.get_status` и т.п. Получившие docstring’и, также улучшат автогенерируемую документацию, если решите её публиковать.

8. **Обновление зависимостей и переход на новые версии** – *(\*Средне, поддержание актуальности\*)*. На будущее, запланировать регулярное обновление ключевых библиотек:

   - Следить за выходом новой версии `gspread` / `gspread-asyncio`. Если `gspread-asyncio` не обновится, принять решение о миграции (как обсуждалось ранее).
   - Обновить `python-telegram-bot` при выходе версии 23 или 24, чтобы получать улучшения и исправления (но учесть возможные изменения API).
   - Поднять минимальную версию Python до 3.11 после окончания поддержки 3.10 (окт 2025), и обеспечить совместимость с Python 3.12+.

   Эти задачи не требуют немедленного выполнения, но их стоит отслеживать. Интеграция Dependabot (п.5) значительно поможет в этом процессе.

### 5. Улучшения процесса разработки и развертывания

1. **Использование системы управления задачами (Issues)** – *(\*Легко, полезно для организации\*)*. Начать вести GitHub Issues даже для собственных идей и багов. Например, завести задачи на реализацию поддержки нескольких целей, на рефакторинг архитектуры (пункты из этого roadmap могут быть оформлены как Issues). Это создаст публичный бэклог. Даже если разработчик один, практика ведения задач дисциплинирует и показывает другим, над чем работа идет. При появлении внешних контрибьюторов, им будет проще понять, что можно взять в работу.
2. **Практика релизов с тегами** – *(\*Легко, полезно для деплоя\*)*. Ввести понятие версий релиза. Например, после реализации нескольких крупных изменений выпустить версию `v1.2` (уже упоминалась версия 1.1 в changelog). Оформить GitHub Release: указать список изменений (из CHANGELOG), прикрепить при желании актуальную PDF-презентацию. Далее, **изменить подход к деплою на сервер**: вместо того, чтобы cron тянул любую правку в `main`, привязать обновление сервера к созданию новых релизов. Например, скрипт `update-bot.sh` можно доработать так, чтобы он проверял не просто `git pull origin main`, а `git fetch --tags` и разворачивал последний тег. Либо вообще отказаться от cron, а запускать деплой через GitHub Actions по событию релиза (Action будет подключаться по SSH к серверу или использовать Deploy Key, чтобы запуллить новую версию). Это защитит продакшен-бота от возможных нестабильностей промежуточных коммитов и позволит откатиться к предыдущему релизу, если что-то пойдет не так.
3. **Контейнеризация и окружение** – *(\*Средне, полезно при масштабировании\*)*. Хотя Docker уже поддерживается, можно улучшить:
   - Проверить, работает ли образ на разных платформах (linux/arm, если, например, запускать на Raspberry Pi). Если нет – внести правки в Dockerfile (возможно, установить системные пакеты для Google credentials).
   - Добавить в README раздел про переменные окружения (например, указать, что надо получить JSON ключей Google и путь прописать, где взять TELEGRAM_BOT_TOKEN).
   - (Опционально) Настроить GitHub Actions workflow для сборки Docker-образа и публикации его (например, на Docker Hub) при создании релиза. Это упростит деплой: вместо ручного разворачивания можно будет просто запускать выкачанный образ.
4. **Branch protection и код-ревью** – *(\*Легко, повышает надежность\*)*. Включить защиту ветки `main` в настройках GitHub: потребовать прохождения всех проверок CI перед мерджем и как минимум одного review (если в проекте появятся другие Maintainer’ы). Сейчас разработчик один, но можно пригласить коллег просматривать код изменений – внешний взгляд улучшает качество. Также стоит включить требование подписывать коммиты (Signed-off-by) и включить сканирование секретов от GitHub (Secret Scanning) – это бесплатные функции, повышающие безопасность.

------

Исполнение данного плана сделает проект более масштабируемым, устойчивым и привлекательным для сообщества. **Приоритетными** шагами являются поддержка **множественных целей** (т.к. это заявленный новый функционал) и небольшие улучшения репозитория (описание, шаблоны) – они легки в реализации и сразу дадут эффект. Далее, по мере роста кода, важны архитектурные рефакторинги и оптимизации (DI, кэш, rate-limit) для поддержания качества. Такой roadmap позволит эволюционировать Target Assistant Bot из персонального проекта в надежное много-пользовательское приложение, сохраняя при этом высокое качество кода и документации.